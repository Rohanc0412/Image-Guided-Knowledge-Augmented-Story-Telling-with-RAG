{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b5f114-5db5-4bc4-9467-2b6eb89e1fc5",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4306cf19-485c-4e0e-8ef9-0a5f875cfcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rohan\\anaconda3\\envs\\llm_proj\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02916c2b-afe5-44c1-a099-d8b960bea486",
   "metadata": {},
   "source": [
    "#### Pre-processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fe7827-72ee-42ce-8d1c-c2dfb67c5ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Corpus successfully loaded.\n",
      "Available columns in the corpus: ['filename', 'img_id', 'caption', 'Event 1', 'Event 2']\n",
      "Prepared 400 passages from events.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\x20-\\x7E]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "    \n",
    "corpus_path = \"./sampling_img_kc/knowledge_corpus.csv\"\n",
    "try:\n",
    "    corpus_df = pd.read_csv(corpus_path, encoding='latin1')\n",
    "    print(\"Knowledge Corpus successfully loaded.\")\n",
    "except UnicodeDecodeError as e:\n",
    "    print(\"Error with 'latin1' encoding:\", e)\n",
    "\n",
    "print(\"Available columns in the corpus:\", corpus_df.columns.tolist())\n",
    "\n",
    "passages = []\n",
    "\n",
    "for idx, row in corpus_df.iterrows():\n",
    "\n",
    "    caption = clean_text(row[\"caption\"]) if \"caption\" in row else \"\"\n",
    "    filename = clean_text(row[\"filename\"]) if \"filename\" in row else \"\"\n",
    "    img_id = row[\"img_id\"]\n",
    "\n",
    "    event1 = clean_text(row[\"Event 1\"]) if \"Event 1\" in row else \"\"\n",
    "    if event1 and event1.lower() != 'nan':\n",
    "        passages.append({\n",
    "            \"id\": f\"{idx}_event1\",\n",
    "            \"text\": event1,\n",
    "            \"metadata\": {\n",
    "                \"filename\": filename,\n",
    "                \"img_id\": img_id,\n",
    "                \"caption\": caption,\n",
    "                \"event_type\": \"Event 1\",\n",
    "                \"event_text\": event1\n",
    "            }\n",
    "        })\n",
    "    event2 = clean_text(row[\"Event 2\"]) if \"Event 2\" in row else \"\"\n",
    "    if event2 and event2.lower() != 'nan':\n",
    "        passages.append({\n",
    "            \"id\": f\"{idx}_event2\",\n",
    "            \"text\": event2,\n",
    "            \"metadata\": {\n",
    "                \"filename\": filename,\n",
    "                \"img_id\": img_id,\n",
    "                \"caption\": caption,\n",
    "                \"event_type\": \"Event 2\",\n",
    "                \"event_text\": event2\n",
    "            }\n",
    "        })\n",
    "\n",
    "print(f\"Prepared {len(passages)} passages from events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505d73c-9ae6-4bbc-b4c9-653c0dbda1fc",
   "metadata": {},
   "source": [
    "#### Loading Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7bade1-9080-4143-b4fe-0a93bcb2eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('multi-qa-mpnet-base-cos-v1')\n",
    "print(\"Embedding model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4800a-6b06-466e-a52e-88d7df1c91f9",
   "metadata": {},
   "source": [
    "#### Creating Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9a6a6-6675-4c58-a41c-34f8be3c5ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index: llm-proj\n"
     ]
    }
   ],
   "source": [
    "pinecone_api_key = \"your_api_key\"\n",
    "pinecone_region = \"us-east-1\"\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "index_name = \"llm-proj\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('multi-qa-mpnet-base-cos-v1')\n",
    "dim = embedding_model.get_sentence_embedding_dimension()\n",
    "\n",
    "indexes = pc.list_indexes().names()\n",
    "if index_name not in indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dim,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region=pinecone_region\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Using existing index: {index_name}\")\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23a43b-e39a-4303-8291-8af2379136f2",
   "metadata": {},
   "source": [
    "#### Embedding and Upserting Passages into Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e4bfaa-436c-498f-aa55-f3747d8e3fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for passages...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf3425242fd40edab7175fcbae1f5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted separate event passages into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "texts = [p[\"text\"] for p in passages]\n",
    "ids = [p[\"id\"] for p in passages]\n",
    "\n",
    "print(\"Computing embeddings for passages...\")\n",
    "embeddings = embedding_model.encode(texts, show_progress_bar=True).tolist()\n",
    "\n",
    "vectors = []\n",
    "for i, emb in enumerate(embeddings):\n",
    "    vectors.append((ids[i], emb, passages[i][\"metadata\"]))\n",
    "\n",
    "index.upsert(vectors=vectors)\n",
    "print(\"Upserted separate event passages into Pinecone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b8181-7124-4729-973d-b6ceadb28b4b",
   "metadata": {},
   "source": [
    "#### Retrieving Passages from Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4151eeac-377b-4dba-ad49-f2a418060094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_facts(image_caption, top_k=5):\n",
    "\n",
    "    raw_query_embedding = embedding_model.encode([example_caption])[0]\n",
    "    query_embedding = np.array(raw_query_embedding, dtype=np.float32).tolist()\n",
    "    query_response = index.query(\n",
    "                        vector=query_embedding,\n",
    "                        top_k=2,\n",
    "                        include_values=True,\n",
    "                        include_metadata=True,\n",
    "                        )\n",
    "    retrieved_items = [match['metadata'] for match in query_response['matches']]\n",
    "    return retrieved_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291a4cdb-2256-44a1-b8a1-3cdf84de7c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Metadata:\n",
      "{'caption': 'An old man, wearing a black beret and a black and red jacket, rides a pony in a desolate mountain location.', 'event_text': 'n the mid-20th century, Australian horseman and writer Ern Pedler embarked on a remarkable solo journey across the vast and arid landscapes of the Australian Outback. Dressed in traditional riding attire, including a wide-brimmed hat and durable riding clothes, Pedler traversed the desolate terrains on horseback, documenting his experiences and the challenges faced in such a remote environment. His journey not only showcased his resilience and horsemanship but also highlighted the profound solitude and beauty of the Australian wilderness. Pedler\\'s writings, such as \"The Big Lonely Horse,\" provide a vivid account of his adventures and the deep bond formed with his horse during this expedition.', 'event_type': 'Event 1', 'filename': '284105062.jpg', 'img_id': 8845.0}\n",
      "{'caption': 'An old man, wearing a black beret and a black and red jacket, rides a pony in a desolate mountain location.', 'event_text': 'In the Scottish Highlands, pony trekking has been a cherished tradition, allowing individuals to explore the rugged and remote landscapes on horseback. Elderly riders often participate in these treks, donning traditional attire such as berets and weather-resistant jackets to navigate the challenging terrains. These expeditions offer a unique blend of adventure and nostalgia, connecting riders with the rich cultural heritage of the region. For instance, a 95-year-old man was documented riding a horse, showcasing that age does not diminish the desire for exploration and connection with nature.', 'event_type': 'Event 2', 'filename': '284105062.jpg', 'img_id': 8845.0}\n"
     ]
    }
   ],
   "source": [
    "example_caption = \"a man in a red jacket riding a small horse\"\n",
    "try:\n",
    "    retrieved_items = retrieve_facts(example_caption, top_k=5)\n",
    "    print(\"Retrieved Metadata:\")\n",
    "    for item in retrieved_items:\n",
    "        print(item)\n",
    "except Exception as e:\n",
    "    print(\"Error during query:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65cb63-9d71-48ff-8bd5-8b6699b73f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Env",
   "language": "python",
   "name": "llm_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
